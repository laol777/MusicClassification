работа выполнена на языке python

зависимости pydub, librosa, keras, theano

в основном в процессе решения опирался на данную статью:

http://benanne.github.io/2014/08/05/spotify-cnns.html

Так так в задании было указано требование - предсказание с точностью не менее 0.8, то я предположил, что метрикой оценивания является accuracy
В качестве обучающей выборки я использовал данные, разбитые по классам в соответсвии с моделью MIREX.

Данные извлекал с сайта musicbed.com, так как там более одназначная классификация. Учитывал то, что классы пересекаются, удалил пересечение классов.
В данных присутвуют watermarks. Они повторяется каждые 20 секунд, начиная от интервале [7;10] секунды, продолжительностью 1 секунда.

Удалил эти watermarks - удалял 3 секунды трека кажные 20 секунд. Далее отрезал от трека начало ~ 7 секунд, из соображений, что в начале трека может присутствовать проигрыш, по которому не всегда однозначно можно определить настроение трека.

Далее разобил оставшийся трек на куски продолжительностью в 17 секунд - для определения настроение трека этого будет достаточно и этим я увеличил обучающую выборку. При этом я буду учитывал то, что в конечном итоге я хочу получить сбалансированную выборку. На валидацию оставил музыкальные треки, не учавствовших в обучении.

Так как данные скачаны из одного источника, пересечение классов буду смотрел по имени трека.
Не смог понять значимого отличия 4 кластера(Witty, Humorous, Whimsical, Wry, Campy, Quirky, Silly) от остальных, удалил этот класс. Итого классификация будет производиться по 4 классам(здесь классификация, соответвенно меткам классов на сайте musicbed.ru): Tense, Angry, Happy, Sad.

Сбор датасета произвел вручную, так как структура веб страницы сложная и нецелесообразно тратить время для написания кода, при требование в малых количествах исходных данных.

Собрано данных без обработки Angry - 125, Happy - 134, Sad - 129, Tense - 123 трека.

Преобразовал стерео аудиозапись в моно.

Для преобразование в log mel spectrogram буду использовал librosa

Далее предсказание класса буду выполнял с помощью сверточной нейронной сети. Предварительно полученные данные с предущего шага отнормировал в диапазоне [-1,1]
Для работы с CNN буду использовать keras и theano, обучая на GPU GTX 760. Архитектура сети представлена в _3_trainCNN.

Финальный размер обучающей выборки взят по 600 семплов на класс. Итого в обучающей выборке 2400 семплов.

Моя сеть обучалась достаточно долго 8.5 часов - не имею возможности запустить kfold == 5, сделал более простую валидадацию: в процессе обучения валидационную выборку 220(качетво 0.8045) и отложенную выборку == 200(качетво 0.74). Моя оценка этого решения - хоть я и не добился должного качества на второй выборке, но считаю, что все же оценка завышена по 2 причинам: 

1) исходная музыка уже поделена каким-то алгоритмом, а не человеком.
2) я не следил за качеством валивационной выборки - возможны случаи, когда семплы берутся из одного трека, что даст немного завышенную оценку.