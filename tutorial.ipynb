{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasagne Tutorial\n",
    "\n",
    "_This tutorial assumes basic knowledge of Theano.  [Here](http://nbviewer.ipython.org/github/craffel/theano-tutorial/blob/master/Theano%20Tutorial.ipynb) is a Theano tutorial if you need to get up to speed._\n",
    "\n",
    "Theano is increadibly useful for compiling and automatically differentiating symbolic expressions transparently on a CPU or GPU.  While it is designed with the application of large neural networks in mind, it has relatively little functionality towards that end.  [Lasagne](https://github.com/benanne/Lasagne/) is a Python module built on top of Theano which provides useful classes and functions which make building neural network models simple.  It has been designed to extend Theano's functionality, so it generally follows Theano's conventions and methods typically accept and return Theano expressions.  In this way, it makes constructing commonly used network structures easy but also allows for arbitrary/unconventional models.  It's also meant to provide a reference implementation which is highly optimized.  Lasagne is developed by a diverse group of researchers with different applications in mind, which ensures that it is both generic and coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named lasagne",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-154aef6f2fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named lasagne"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "IPython.display.Image(\"http://static-vegetariantimes.s3.amazonaws.com/wp-content/uploads/2009/03/10851medium.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy example\n",
    "\n",
    "As a toy example to demonstrate functionality, we'll train a standard multi-layer perceptron on a simple synthetic two-dimensional four-class dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "N_CLASSES = 4\n",
    "X, y = sklearn.datasets.make_classification(\n",
    "    n_features=2, n_redundant=0,\n",
    "    n_classes=N_CLASSES, n_clusters_per_class=1)\n",
    "# Convert to theano floatX\n",
    "X = X.astype(theano.config.floatX)\n",
    "# Labels should be ints\n",
    "y = y.astype('int32')\n",
    "# Make a scatter plot where color encodes class\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredients: `layers`\n",
    "\n",
    "What is lasagne made out of?  A stack of layers of noodles, sauce, cheeses, etc.  Just like making lasagne, constructing a network in `lasagne` typically involves stacking `Layer` subclass instances.  Much of Lasagne's functionality centers around subclasses of the `Layer` class.  A typical `Layer` subclass is an implementation of some kind of commonly used neural network layer, and contains the layer's parameters as well as methods for computing the Theano expression of the network given a Theano tensor variable used as input.  Most `Layer`s are initialized with a pointer to their input layer.  The output of the network can be generated using the `lasagne.layers.get_output` method, which recursively computes a symbolic Theano expression for the output of all layers given an input.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `InputLayer`\n",
    "\n",
    "The class `InputLayer` is a special layer type which stops the recurision and allows the user to input actual data into the network.  It also, for convenience, instantiates a Theano tensor variable `input_var` of the right type given the shape you provide it.  The `input_var` variable is used by default to compute the symbolic Theano expression of the network (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, construct an input layer.\n",
    "# The shape parameter defines the expected input shape, which is just the shape of our data matrix X.\n",
    "l_in = lasagne.layers.InputLayer(shape=X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DenseLayer`\n",
    "\n",
    "The `DenseLayer` is the basic building block of the neural network: It computes a linear mix of the input $x$ using a weight matrix $W$ and a bias vector $b$, and then applies a nonlinearity $\\sigma$, yielding $\\sigma(Wx + b)$.  The `DenseLayer` class keeps track of the parameters and how to use them to compute this expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll create a network with two dense layers: A tanh hidden layer and a softmax output layer.\n",
    "l_hidden = lasagne.layers.DenseLayer(\n",
    "    # The first argument is the input layer\n",
    "    l_in,\n",
    "    # This defines the layer's output dimensionality\n",
    "    num_units=10,\n",
    "    # Various nonlinearities are available\n",
    "    nonlinearity=lasagne.nonlinearities.tanh)\n",
    "# For our output layer, we'll use a dense layer with a softmax nonlinearity.\n",
    "l_output = lasagne.layers.DenseLayer(\n",
    "    l_hidden, num_units=N_CLASSES, nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `get_output`\n",
    "\n",
    "To actually compute the Theano expression of a stack of `Layer` subclass instances, use the `get_output` function from `lasagne.layers`.  As mentioned above, by default `get_output` will compute the output given the input variable `input_var` of the `InputLayer` at the base of the network.  You can also pass a Theano symbolic variable to get the output of the network with respect to that variable instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_output = lasagne.layers.get_output(l_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasting: `objectives`\n",
    "\n",
    "When making a lasagna, you need a way to decide when it's ready to eat.  A talented lasagne cook can do this by tasting it.  Machine learning practitioners use objective functions to decide when their neural network is ready to use, i.e. has been successfuly trained.  `lasagne`'s `objectives` submodule provides convenient functions for computing a symbolic Theano expression for an objective function.  Usually this involves comparing the output of a network to a true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As a loss function, we'll use Lasagne's categorical_crossentropy function.\n",
    "# This allows for the network output to be class probabilities,\n",
    "# but the target output to be integers denoting the class.\n",
    "true_output = T.ivector('true_output')\n",
    "loss = T.mean(lasagne.objectives.categorical_crossentropy(net_output, true_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baking: `updates`\n",
    "\n",
    "After assembling a lasagna, you need to bake it until it's ready to eat.  Getting a neural network ready to use is done by optimizing its parameters with respect to the objective.  Lasagne crucially provides functionality for constructing updates to optimize the network's parameters according to some objective (i.e. train it).  This makes it easy to, for example, train a network with stochastic gradient descent (or something more fancy like AdaGrad).  Computing the updates typically involves collecting the network's parameters using `get_all_params` then using a function in `lasagne.updates`.  The resulting updates list can then be fed into a `theano.function` to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieving all parameters of the network is done using get_all_params,\n",
    "# which recursively collects the parameters of all layers connected to the provided layer.\n",
    "all_params = lasagne.layers.get_all_params(l_output)\n",
    "# Now, we'll generate updates using Lasagne's SGD function\n",
    "updates = lasagne.updates.sgd(loss, all_params, learning_rate=1)\n",
    "# Finally, we can compile Theano functions for training and computing the output.\n",
    "# Note that because loss depends on the input variable of our input layer,\n",
    "# we need to retrieve it and tell Theano to use it.\n",
    "train = theano.function([l_in.input_var, true_output], loss, updates=updates)\n",
    "get_output = theano.function([l_in.input_var], net_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train (bake?) for 100 epochs\n",
    "for n in xrange(100):\n",
    "    train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1080d550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEKCAYAAAALoA6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQwihoaKAhxBCQ/0G6NTA5pteTJ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107cce90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the predicted label of the training data.\n",
    "# The argmax converts the class probability output to class label\n",
    "y_predicted = np.argmax(get_output(X), axis=1)\n",
    "# Plot incorrectly classified points as black dots\n",
    "plt.scatter(X[:, 0], X[:, 1], c=(y != y_predicted), cmap=plt.cm.gray_r)\n",
    "# Compute and display the accuracy\n",
    "plt.title(\"Accuracy: {}%\".format(100*np.mean(y == y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world example (MNIST ConvNet)\n",
    "\n",
    "The above example illustrates the simplest possible usage of `lasagne`.  Fortunately, it's also useful for real-world problems.  Here, we'll train a convolutional network to classify MNIST digits.  This example is based on the [`mnist.py`](https://github.com/benanne/Lasagne/blob/master/examples/mnist.py) script included with Lasagne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-43d3b843679d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# We'll use the load_data function from the mnist.py example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#from mnist import load_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create a dataset dictionary for convenience\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m dataset = {\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# We'll use the load_data function from the mnist.py example\n",
    "#from mnist import load_dataset\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_dataset()\n",
    "# Create a dataset dictionary for convenience\n",
    "dataset = {\n",
    "    'train': {'X': X_train, 'y': y_train},\n",
    "    'valid': {'X': X_valid, 'y': y_valid}}\n",
    "# Plot an example digit with its label\n",
    "plt.imshow(dataset['train']['X'][0][0], interpolation='nearest', cmap=plt.cm.gray)\n",
    "plt.title(\"Label: {}\".format(dataset['train']['y'][0]))\n",
    "plt.gca().set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet Input\n",
    "\n",
    "In `lasagne`, the convention for a 2D convolutional network is that the data's shape throughout the network is `(n_examples, n_channels, width, height)`.  Since MNIST digits has a single channel (they're grayscale images), `n_channels = 1` for the input layer; if we were dealing with RGB images we'd have `n_channels = 3`.  Within the network, `n_channels` is the number of filter kernels of each layer.\n",
    "\n",
    "Conveniently, we can make the first dimension (the \"number of example\" dimension) variable.  This comes in handy when you pass your network training examples in minibatches, but want to evaluate the output on the entire validation or test set.  This is designated by setting the first entry of the shape passed to the `InputLayer` to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll determine the input shape from the first example from the training set.\n",
    "input_shape = dataset['train']['X'][0].shape\n",
    "l_in = lasagne.layers.InputLayer(\n",
    "    shape=(None, input_shape[0], input_shape[1], input_shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layers\n",
    "\n",
    "The basic 2D convolutional layer in Lasagne is `Conv2DLayer`.  This uses Theano's built-in convolution operation to convolve a collection 2D filter against the last two dimensions of its inputs.  Theano's convolution operation is smart enough to use a more efficient backend (e.g. `cudnn`) when possible and available.\n",
    "\n",
    "#### Note on parameter initialization\n",
    "\n",
    "The initialization used for each parameter in each layer can be a Numpy `ndarray`, a Theano shared variable, or an `Initializer` subclass from `lasagne.init`.  Many common initialization schemes are included in Lasagne for convenience.  For example, below we'll be initializing the convolutional layer weights using the approach proposed by He et. al. in [\"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\"](http://arxiv.org/abs/1502.01852).  This approach initializes the weights by sampling a Gaussian distribution with zero mean and $\\sigma = \\sqrt{\\frac{2}{n\\_in}}$, where $n\\_in$ is the number of inputs to the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the first convolutional layer\n",
    "l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "    l_in,\n",
    "    # Here, we set the number of filters and their size.\n",
    "    num_filters=32, filter_size=(5, 5),\n",
    "    # lasagne.nonlinearities.rectify is the common ReLU nonlinearity\n",
    "    nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    # Use He et. al.'s initialization\n",
    "    W=lasagne.init.HeNormal(gain='relu'))\n",
    "# Other arguments: Convolution type (full, same, or valid) and stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layers\n",
    "\n",
    "2D max pooling is straightforward: Use the `MaxPool2DLayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, we do 2x2 max pooling.  The max pooling layer also supports striding\n",
    "l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The second convolution/pooling pair is the same as above.\n",
    "l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "    l_pool1, num_filters=32, filter_size=(5, 5),\n",
    "    nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    W=lasagne.init.HeNormal(gain='relu'))\n",
    "l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layers\n",
    "\n",
    "We'll be using a single hidden layer and a dense output layer with dropout in between.  As is the convention in convnets, the hidden layer will use a ReLU nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_hidden1 = lasagne.layers.DenseLayer(\n",
    "    l_pool2, num_units=256, \n",
    "    nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    W=lasagne.init.HeNormal(gain='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "Dropout in Lasagne is implemented as a `Layer` subclass.  By placing a `DropoutLayer` between layers, the connections between the two layers will randomly be dropped.  As we'll see later, setting `get_output` or `get_loss`'s keyword argument `deterministic` to `True` will make the `DropoutLayer` act as a simple pass-through, which is useful when computing the output of the network after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p is the dropout probability\n",
    "l_hidden1_dropout = lasagne.layers.DropoutLayer(l_hidden1, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_output = lasagne.layers.DenseLayer(\n",
    "    l_hidden1_dropout,\n",
    "    # The number of units in the softmas output layer is the number of classes.\n",
    "    num_units=10,\n",
    "    nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives, updates, and training\n",
    "\n",
    "This part of the code will look very similar to above - we'll define an objective, compute some updates, use the updates to compile Theano functions, then use the functions to train the network and compute its output given some input.  Since this problem is a little harder than our toy example, we'll use ADADELTA, a fancier stochastic optimization technique, described in [ADADELTA: An Adaptive Learning Rate Method](http://arxiv.org/abs/1212.5701).  There's plenty of others to choose from in `lasagne.updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, let's train it!  We'll chop the training data into mini-batches,\n",
    "# and compute the validation accuracy every epoch.\n",
    "BATCH_SIZE = 100\n",
    "N_EPOCHS = 10\n",
    "# Keep track of which batch we're training with\n",
    "batch_idx = 0\n",
    "# Keep track of which epoch we're on\n",
    "epoch = 0\n",
    "while epoch < N_EPOCHS:\n",
    "    # Extract the training data/label batch and update the parameters with it\n",
    "    train(dataset['train']['X'][batch_idx:batch_idx + BATCH_SIZE],\n",
    "          dataset['train']['y'][batch_idx:batch_idx + BATCH_SIZE])\n",
    "    batch_idx += BATCH_SIZE\n",
    "    # Once we've trained on the entire training set...\n",
    "    if batch_idx >= dataset['train']['X'].shape[0]:\n",
    "        # Reset the batch index\n",
    "        batch_idx = 0\n",
    "        # Update the number of epochs trained\n",
    "        epoch += 1\n",
    "        # Compute the network's output on the validation data\n",
    "        val_output = get_output(dataset['valid']['X'])\n",
    "        # The predicted class is just the index of the largest probability in the output\n",
    "        val_predictions = np.argmax(val_output, axis=1)\n",
    "        # The accuracy is the average number of correct predictions\n",
    "        accuracy = np.mean(val_predictions == dataset['valid']['y'])\n",
    "        print(\"Epoch {} validation accuracy: {}\".format(epoch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hmm... maybe MNIST is a toy example too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Networks\n",
    "\n",
    "Lasagne incudes classes for a \"vanilla\" (densely connected) recurrent layer, a recurrent layer with arbitrary input-to-hidden and hidden-to-hidden connections, an LSTM layer, and a GRU layer.  The usage is a little different due to the fact that the network expects batches time sequences as input; here we will demonstrate usage on a common long-term memory benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"add\" task\n",
    "\n",
    "In \"[Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\", the paper which proposed the LSTM unit, a handful of tasks are proposed which are meant to test a model's ability to handle long-term dependencies.  Here, we will use the \"add\" task, in which a two-dimensional time series is presented to the model where one dimension is sampled uniformly from $[0, 1]$ and the other is all zeros except at two samples where it is 1.  The goal for each time series is to output the sum of the values in the first dimension at the indices where the second dimension is 1.  For example, the target for the following\n",
    "\n",
    "    | 0.5 | 0.7 | 0.3 | 0.1 | 0.2 | ... | 0.5 | 0.9 | ... | 0.8 | 0.2 |\n",
    "    |  0  |  0  |  1  |  0  |  0  |     |  0  |  1  |     |  0  |  0  |\n",
    "\n",
    "would be 0.3 + .9 = 1.2.  The `recurrent.py` example includes a function `gen_data` which generates data for this task; we'll use this function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recurrent import gen_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent layer shape conventions\n",
    "\n",
    "Because recurrent layers are used in tasks where the sequential nature of the input data matters, an additional dimension is needed beyond the `(batch_size, n_features_1, n_features_2, ...)` shape expected by convolutional and dense layers.  We could, of course, use the first dimension as the \"number of sequence steps\" dimension, but that would mean that we could not present minibatches of sequences to the network, which would slow down training and probably hurt convergence.  So, the convention used in `lasagne` is that sequential data is presented in the shape `(batch_size, n_time_steps, n_features_1, n_features_2, ...)`.\n",
    "\n",
    "#### Masks\n",
    "Because not all sequences in each minibatch will always have the same length, all recurrent layers in `lasagne` accept a separate mask input which has shape `(batch_size, n_time_steps)`, which is populated such that `mask[i, j] = 1` when `j <= (length of sequence i)` and `mask[i, j] = 0` when `j > (length of sequence i)`.  When no mask is provided, it is assumed that all sequences in the minibatch are of length `n_time_steps`.\n",
    "\n",
    "#### Variable number of time steps\n",
    "\n",
    "Finally, as is true of the first (`batch_size`) dimension, the `n_time_steps` dimension can be set to `None`, which means that it can vary from batch to batch.  This means that the network can take in minibatches which have an arbitrary number of sequences which are of arbitrary length - very convenient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By setting the first and second dimensions to None, we allow\n",
    "# arbitrary minibatch sizes with arbitrary sequence lengths.\n",
    "# The number of feature dimensions is 2, as described above.\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None, 2))\n",
    "# This input will be used to provide the network with masks.\n",
    "# Masks are expected to be matrices of shape (n_batch, n_time_steps);\n",
    "# both of these dimensions are variable for us so we will use\n",
    "# an input shape of (None, None)\n",
    "l_mask = lasagne.layers.InputLayer(shape=(None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent layers\n",
    "\n",
    "The interface for `RecurrentLayer`, `GRULayer`, and `LSTMLayer` are all pretty similar.  Here, we will be using the `LSTMLayer`, which has the most construction arguments; usage of the other layers will generally be a little simpler!\n",
    "\n",
    "#### Parameter initialization\n",
    "\n",
    "In order to cut down on the number of constructor arguments and make changing initialization schemes more convenient, the `GRULayer` and `LSTMLayer` utilize the `Gate` class, which is essentially just a container for parameter initializers.  The `LSTMLayer` initializer accepts four `Gate` instances - one for the input gate, one for the forget gate, one for the cell, and one for the output gate.  Here, we will demonstrate how to change the weight initialization for all gates to use orthogonal initialization, which (anecdotally) can facilitate learning in RNNs.  Note that the cell \"gate\" doesn't use a weight matrix for a cell connection (that wouldn't make sense), and it uses a different nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All gates have initializers for the input-to-gate and hidden state-to-gate\n",
    "# weight matrices, the cell-to-gate weight vector, the bias vector, and the nonlinearity.\n",
    "# The convention is that gates use the standard sigmoid nonlinearity,\n",
    "# which is the default for the Gate class.\n",
    "gate_parameters = lasagne.layers.recurrent.Gate(\n",
    "    W_in=lasagne.init.Orthogonal(), W_hid=lasagne.init.Orthogonal(),\n",
    "    b=lasagne.init.Constant(0.))\n",
    "\n",
    "cell_parameters = lasagne.layers.recurrent.Gate(\n",
    "    W_in=lasagne.init.Orthogonal(), W_hid=lasagne.init.Orthogonal(),\n",
    "    # Setting W_cell to None denotes that no cell connection will be used.\n",
    "    W_cell=None, b=lasagne.init.Constant(0.),\n",
    "    # By convention, the cell nonlinearity is tanh in an LSTM.\n",
    "    nonlinearity=lasagne.nonlinearities.tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LSTMLayer` options\n",
    "\n",
    "Apart from taking in the layer's input connection, the number of units, and `Gate` instances for parameter initialization, the `LSTMLayer` has a variety of other constructor arguments which determine the behavior of the layer.  As mentioned above, many of these arguments are shared by the other recurrent layers.\n",
    "\n",
    "#### Cell and hidden state initialization\n",
    "\n",
    "The layer's state at the beginning of the sequence can be set by passing initializers to the `cell_init` and `hid_init` arguments; by default, they are initialized to zeros.  Somtimes these initial values are learned as parameters of the network, sometimes they aren't; you can decide whether you want to include them as parameters to be learned by setting the `learn_init` argument to `True` or `False`.\n",
    "\n",
    "#### \"Peephole\" connections\n",
    "\n",
    "A common augmentation to the originally propsed LSTM architecture is to include connections from the cell state to the gates.  Some people use this, some people don't, you can decide which you want by setting the `peepholes` argument to `True` or `False`.\n",
    "\n",
    "#### Truncating the number of backpropagation steps\n",
    "\n",
    "The de facto method for training recurrent networks is backpropagation through time, which simply unrolls the network across timesteps and treats it as a network which is repeated for each time step.  This can result in an incredibly \"deep\" and computationally expensive network, so it's common practice to truncate the number of unrolled sequence steps.  This can be controlled with the `gradient_steps` argument; when it's `-1` (the default), this means \"don't truncate\".\n",
    "\n",
    "#### Clipping gradients\n",
    "\n",
    "A common method for mitigating the exponentially growing gradients commonly found when \"unrolling\" recurrent networks through time and backpropagating is to simply preventing them from being larger than a pre-set value.  In recurrent layers, this can be achieved by passing in a float (rather than `False` to `grad_clipping`.\n",
    "\n",
    "#### Unrolling recursion\n",
    "\n",
    "`theano`'s underlying method for recursion, `scan`, isn't terribly efficient.  Some speedup can be achieved (with some additional memory usage) by explicitly using a `for` loop in Python instead of `scan`.  `lasagne` has a utility function for this, `utils.unroll_scan`, which can be swapped in for `theano.scan` by setting `unroll_scan=True`.  Unfortunately, this currently requires that the `n_time_steps` dimension be known beforehand, so we will use the default of `unroll_scan=False`.\n",
    "\n",
    "#### Precomputing input dot products\n",
    "\n",
    "Some of the dot products computed in recurrent layers are non-recursive, which means they can be computed ahead of time in one big dot product.  Since one big dot product is more efficient than lots of little dot products, `lasagne` does it by default.  However, it imposes an additional memory requirement, so if you're running out of memory, set `precompute_input` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our LSTM will have 10 hidden/cell units\n",
    "N_HIDDEN = 10\n",
    "l_lstm = lasagne.layers.recurrent.LSTMLayer(\n",
    "    l_in, N_HIDDEN,\n",
    "    # We need to specify a separate input for masks\n",
    "    mask_input=l_mask,\n",
    "    # Here, we supply the gate parameters for each gate\n",
    "    ingate=gate_parameters, forgetgate=gate_parameters,\n",
    "    cell=cell_parameters, outgate=gate_parameters,\n",
    "    # We'll learn the initialization and use gradient clipping\n",
    "    learn_init=True, grad_clipping=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional recurrence\n",
    "\n",
    "It's often helpful to process sequences simultaneously forwards and backwards.  In `lasagne` this is achieved by using two recurrent layers in parallel, one of which has the `backwards` argument set to `True`.  When `backwards=True`, the sequence is processed in reverse, then the layer's output is reversed so that recurrent layer outputs always go from the start of the sequence to the finish.  The output of the forward and backward layers should then be combined using a `MergeLayer` of some kind - e.g. concatenating their output or summing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The \"backwards\" layer is the same as the first,\n",
    "# except that the backwards argument is set to True.\n",
    "l_lstm_back = lasagne.layers.recurrent.LSTMLayer(\n",
    "    l_in, N_HIDDEN, ingate=gate_parameters,\n",
    "    mask_input=l_mask, forgetgate=gate_parameters,\n",
    "    cell=cell_parameters, outgate=gate_parameters,\n",
    "    learn_init=True, grad_clipping=100., backwards=True)\n",
    "# We'll combine the forward and backward layer output by summing.\n",
    "# Merge layers take in lists of layers to merge as input.\n",
    "l_sum = lasagne.layers.ElemwiseSumLayer([l_lstm, l_lstm_back])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining recurrent and feed-forward layers\n",
    "\n",
    "As mentioned above, recurrent layers and feed-forward layers expect different input shapes.  The output of `l_sum` will be of shape `(n_batch, n_time_steps, N_HIDDEN)`.  If we fed this into a non-recurrent layer, it would think that the `n_time_steps` dimension was a \"feature\" dimension, when in fact it's a \"sample\" dimension.  That is, each index in the second dimension should be treated as a different sample, and a non-recurrent `lasagne` layer would instead treat them as different feature values, which would be incorrect.  Fortunately, the `ReshapeLayer` makes combining these conventions very convenient - we just combine the first and second dimension so that there are essentially `n_batch*n_time_steps` individual samples before using any non-recurrent layers, then (optionally) reshape the output back to the original shape.\n",
    "\n",
    "Now, as mentioned above, we are using `None` in the `n_batch` and `n_time_steps` dimensions to allow for minibatches with an arbitrary number of sequences with an arbitrary number of timesteps.  We can't tell the `ReshapeLayer` exactly what to reshape to, but we can instead just tell it to squash all of the dimensions up to the last by using `-1` for the first dimension.  In order to reshape back to the original shape after using a non-recurrent layer, we can just retrieve the input layer's symbolic shape and use those symbolic variables in another `ReshapeLayer`, so that the correct values will be filled in at compile time.\n",
    "\n",
    "Note that because we will only be using the output of the network at the end of the sequence, this could also be done using a `SliceLayer` (as in the [recurrent.py example](https://github.com/Lasagne/Lasagne/blob/master/examples/recurrent.py) included with `lasagne`) which is a bit more efficient.  In this tutorial, we'll do it with the `ReshapeLayer` for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, retrieve symbolic variables for the input shape\n",
    "n_batch, n_time_steps, n_features = l_in.input_var.shape\n",
    "# Now, squash the n_batch and n_time_steps dimensions\n",
    "l_reshape = lasagne.layers.ReshapeLayer(l_sum, (-1, N_HIDDEN))\n",
    "# Now, we can apply feed-forward layers as usual.\n",
    "# We want the network to predict a single value, the sum, so we'll use a single unit.\n",
    "l_dense = lasagne.layers.DenseLayer(\n",
    "    l_reshape, num_units=1, nonlinearity=lasagne.nonlinearities.tanh)\n",
    "# Now, the shape will be n_batch*n_timesteps, 1.  We can then reshape to\n",
    "# n_batch, n_timesteps to get a single value for each timstep from each sequence\n",
    "l_out = lasagne.layers.ReshapeLayer(l_dense, (n_batch, n_time_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives, updates, and training\n",
    "\n",
    "The rest of the code for training the recurrent network is quite similar to the feed-forward network with two key differences:  First, as mentioned above, a separate `theano` tensor variable `mask` is required to tell the network the length of each sequence in each minibatch, and second, the effectiveness of the network only really depends on the final time step output by the network, so we will simply slice away that value when computing a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Symbolic variable for the target network output.\n",
    "# It will be of shape n_batch, because there's only 1 target value per sequence.\n",
    "target_values = T.vector('target_output')\n",
    "# This matrix will tell the network the length of each sequences.\n",
    "# The actual values will be supplied by the gen_data function.\n",
    "mask = T.matrix('mask')\n",
    "\n",
    "# lasagne.layers.get_output produces an expression for the output of the net\n",
    "network_output = lasagne.layers.get_output(l_out)\n",
    "# The value we care about is the final value produced for each sequence\n",
    "# so we simply slice it out.\n",
    "predicted_values = network_output[:, -1]\n",
    "# Our cost will be mean-squared error\n",
    "cost = T.mean((predicted_values - target_values)**2)\n",
    "# Retrieve all parameters from the network\n",
    "all_params = lasagne.layers.get_all_params(l_out)\n",
    "# Compute adam updates for training\n",
    "updates = lasagne.updates.adam(cost, all_params)\n",
    "# Theano functions for training and computing cost\n",
    "train = theano.function(\n",
    "    [l_in.input_var, target_values, l_mask.input_var],\n",
    "    cost, updates=updates)\n",
    "compute_cost = theano.function(\n",
    "    [l_in.input_var, target_values, l_mask.input_var], cost)\n",
    "\n",
    "# We'll use this \"validation set\" to periodically check progress\n",
    "X_val, y_val, mask_val = gen_data()\n",
    "\n",
    "# We'll train the network with 10 epochs of 100 minibatches each\n",
    "NUM_EPOCHS = 10\n",
    "EPOCH_SIZE = 100\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for _ in range(EPOCH_SIZE):\n",
    "        X, y, m = gen_data()\n",
    "        train(X, y, m)\n",
    "    cost_val = compute_cost(X_val, y_val, mask_val)\n",
    "    print(\"Epoch {} validation cost = {}\".format(epoch + 1, cost_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
